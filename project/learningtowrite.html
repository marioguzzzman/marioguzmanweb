<!DOCTYPE html>
<html>
<!-- made with love. -->
<!-- Developed by Austin DeHaven -->

<!-- Added by HTTrack -->
<meta http-equiv="content-type" content="text/html;charset=utf-8" />
<!-- /Added by HTTrack -->

<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src=""></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'UA-59520421-1');
    </script>

    <title>Mario Guzman</title>
    <meta name="charset" content="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <meta name="description" content="I am a Mexican researcher, experimental writer, and new media artist.

    I focus on the intersection of language studies and audiovisual phenomena in the realms of web development, interactive media, algorithmic literature, and robotics. I have strong experience in designing educational programs merging technology, art, and education.

    I want to bring code, storytelling, and culture together. From my perspective, writing is a performative process that creates meaningful scenarios in which humans and machines participate together in the creation and negotiation of meaning as an interactive experience.">

    <!-- <meta name='description' content='Mario Guzman is a Mexican researcher, experimental writer and new media artist merging language with audiovisual phenomena in the realms of web development, electronic art, algorithmic literature, and robotics. He has a B.A. in Literature from the Universidad de Buenos Aires and a Master in Technology and Aesthetics of Electronic Arts from the Universidad Nacional de Tres de Febrero in Argentina. He explores the communication between human and non-human agents, robot-human interaction, and different ways to encode perception and narrative through technology in the process of bringing code studies, storytelling and culture together.'> -->

    <meta name="keywords" content="Hong Kong, Mexico, interactive design, interactive, glitch, Argentina, Guzman, mario guzman, designer, marioguzzzman, digital literature, robotics, robot, algorithmic literature, photography, mapping">

    <!-- TAGS FOR SOCIAL -->
    <!-- TAGS FOR SOCIAL -->
    <meta name='theme-color' content='white'>
    <meta property='og:type' content='website'>
    <meta property='og:url' content='http://www.mario-guzman.com'>
    <meta property='og:title' content='Portfolio: Mario Guzman'>

    <meta property='og:description' content='Researcher, experimental writer, and new media artist.
    I focus on the intersection of language studies, web development, interactive media, algorithmic literature, and robotics. I want to bring code, storytelling, and culture together.'>

    <meta property='og:image' content='/images/global/mario-guzman-web.jpg'>
    <!-- image must be 600x315 -->


    <link rel="stylesheet" href="https://use.typekit.net/bxp7lue.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,500,600">
    <link rel="stylesheet" href="../stylesheets/global.css" />
    <link rel="stylesheet" href="../stylesheets/top-arrow.css" />
    <link rel="stylesheet" href="../stylesheets/layout.css" />
    <link rel="stylesheet" href="../stylesheets/landing.css" />
    <link rel="stylesheet" href="../stylesheets/project-nav.css" />
    <link rel="stylesheet" href="../stylesheets/projects.css" />
    <link rel="stylesheet" href="../stylesheets/projects/quetzabot.css">
    <link rel="stylesheet" href="https://npmcdn.com/flickity@2/dist/flickity.css" />
    <link rel="stylesheet" href="../stylesheets/footer.css" />

</head>

<body>
    <div class="body-width">

        <div id="headerJS"></div>
        <!-- <div id="back-to-top"></div> -->

        <div class="observable" id="project-overview">
            <div class="project-overview">
                <div class="h1 project-overview-title">
                    Learning to write: a machine learning experiment (2019)
                </div>
                <div class="project-overview-body">
                    <i>Learning to write: a machine learning experiment</i> is a textual artificial organism that performs a reading and writing exercise using video input from around the globe and a generative language model trained on 19th-century travel
                    literature. The work focus on the notion of travel, journey, discovery, and cognition.
                </div>
            </div>

            <!-- Sets DATE, NOT IN USE -->
            <!-- <div class="project-overview-details-row"> -->
            <!--<div class="project-overview-details-column">
                     <span class="project-overview-subhead h4">Client</span>
                    <span class="project-overview-value">Microsoft / Pepsi</span>
                </div>
                <div class="project-overview-details-column">
                    <span class="project-overview-subhead h4">Date</span>
                    <span class="project-overview-value">2015</span> -->
            <!-- </div> -->
            <div class="project-overview-details-column">
                <span class="project-overview-subhead h4">Machine Learning / Experimental Literature /
                    Installation</span>
                <span class="project-overview-value">
                    Machine Learning, convolutional neural network, mobile vision, long short-term memory (LSTM),
                    projection, XIX century travel literature corpus, travel videos.</span>
            </div>
        </div>
    </div>

    <!--<iframe src="https://player.vimeo.com/video/189782745?title=0&portrait=0" width="800" height="450" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>-->


    <div style="height: 900px; width: 100%;">
        <iframe src="https://player.vimeo.com/video/390603479" width="100%" height="100%" frameborder="0" allow="autoplay; fullscreen" allowfullscreen>
        </iframe>
    </div>
    <script src="https://player.vimeo.com/api/player.js"></script>


    <!--
    <img class="lazy full-width spacing-large observable" data-src="/assets/proyectos/quetzabot/quetzabot2.jpg">
-->

    <br><br><br>
    <div class="copy-width spacing-large">
        <p class="observable h1 spacing-copy">Experimenting with narrative.</p>
        <p class="observable body">The work arises from a need to organize a series of chaotic experiences while traveling to more than 39 countries and 1,532 flight hours with a social robot. <br><br> To make sense of the speed and heterogeneity of these episodes, I've designed
            a writing system that articulates two structures: a convolutional neural network using mobile vision and a long short-term memory (LSTM) architecture of recurrent neural network (RNN).
        </p>
    </div>

    <br>
    <div class="body-width-small spacing-large observable parallax-section">
        <div class="parallax-1"><img class="lazy" data-src="/images/projects/lstm/lstm1.png"> </div>
        <div class="parallax-2"> <img class="lazy" data-src="/images/projects/lstm/forest.png"> </div>
        <br>
    </div>

    <div class="copy-width spacing-large">
        <p class="observable h1 spacing-copy">Writing with Neural Networks</p>
        <p class="observable body"> A convolutional neural network using mobile vision interprets a set of audiovisual micro-narratives that represent personal waiting times or moments in which I feel present. <br> <br> Then, the objects and situations recognized by the machine
            are sent to a long short-term memory (LSTM) recurrent neural network (RNN) that has been trained on 19th-century travel literature, the NNR model then narrates what is happening -or what it thinks is happening- in the image.
            <br><br> The work is also an experiment around an endless writing action that tries to understand a world constituted by limited objects and perceptions, perhaps a reflection of our own cognitive operations.
        </p>
    </div>

    <!-- <br>
    <div class="body-width-small spacing-large observable parallax-section">
        <div class="parallax-2"><img class="lazy" data-src="/images/projects/lstm/networks.png"> </div>
        <div class="parallax-1"> <img class="lazy" data-src="/images/projects/oraculo/oraculo5.png"> </div>
        <br>
    </div> -->

    <!-- 
    <video class="spacing-standard body-width-small observable" width="100%" playsinline muted loop autoplay>
    <source src="../images/projects/xbox/tech-overview.mp4" type="video/mp4">
  </video>
     -->

    <!--<div class="xbox-site-video observable spacing-large">
        <div class="macbook">
            <img class="image-position" src="../images/projects/xbox/macbook.png" />
            <video class="video-position" width="100%" playsinline muted loop autoplay>
        <source src="../images/projects/xbox/screencapture.mp4" type="video/mp4">
      </video>
        </div>
    </div>

    <div class="copy-width spacing-large">
        <p class="observable h1 spacing-copy">Aesthetics.</p>
        <p class="observable body">A good portion of the site’s aesthetic took inspiration from the Xbox One X launch video, but we also pulled inspiration from all kinds of existing design patterns in the gaming comunity. This includes things like heads up displays, dashboard,
            etc.
        </p>
    </div>

    <div class="body-width-small">
        <img style="min-height: 600px;" class="lazy spacing-large observable" data-src="/images/projects/lstm/networks.png">
    </div>
-->


    <!-- <div class="projects" data-scroll-target="true">
        <div class="project-100 project">
            <picture>
                <source media="(max-width: 765px)" srcset="/images/projects/lstm/networks.png">
                <img alt="Quetzalcoatl-bot" src="/images/projects/lstm/networks.png">
            </picture>
        </div>
        <br><br>
    </div> -->

    <!--<div class="bump">

        <div class="copy-width spacing-large">
            <p class="observable h1 spacing-copy">Counter-writing.</p>
            <p class="observable body"> The work displays a kind writing that accentuates the resistance of matter and abandons the conservation of information in favor of a fading movement of signs. Counter-writing thus performs against the traditional and social function of the
                codex - safeguarding information and preserving a mythological narrative - to impose on it the logic of the eternal beginning, the blank page or the eternal vacuum.
            </p>
            <br>
            <p class="observable body">
                If writing as technology supposes a state of conservation and, therefore, a triumph over the wear of materials and the loss of memory, this work proposes the inverse movement and bets for distortion, fragmentation, and fading.
            </p>
    </div>
    </div>-->


    <div class="full-width carousel spacing-large">
        <div class="carousel-cell observable"><img src="/images/projects/lstm/networks.png"></img>
        </div>
    </div>


    <div class="team body-width-small spacing-large">
        <div class="col">
            <p class="observable h1 spacing-copy">Exhibitions</p>

            <p class="observable body"><strong>Game on! The art in games.</strong>
                <span class="text-muted">San Martín Cultural Center, Buenos Aires,
                    2019.</span><br />
            </p>

            <p class="observable body"><strong>Mixed feelings.</strong> <span class="text-muted">Bots and Machine
                    Learning: Chatbots, Artbots
                    and Machine Learning for Web Application. School Of Machines, Making & Make–Believe, Berlin,
                    Germany, 2019.</span><br />
            </p>
        </div>

        <div class="col">
            <p class="observable h1 spacing-copy">Press</p>
            <p class="observable body">
                <a class="modal_link" href="http://www.gameon2019.com/speaker/s-t-mario-guzman">
                    <strong>Latino-American literary mirror: and experiment with Machine Learning.
                </strong><span class="text-muted"></span></a>
                <br /></p>
        </div>
    </div>

    <!-- <div style="height: 900px; width: 100%;">
        <iframe src="https://player.vimeo.com/video/164745555?title=0&portrait=0" width="100%" height="100%"
            frameborder="0" allow="autoplay; fullscreen" allowfullscreen>
        </iframe>
    </div>
    <script src="https://player.vimeo.com/api/player.js"></script> -->


    <!-- Footer -->

    <div id="footerJS"></div>

    <!-- ----------------------------- Scripts ----------------------------- -->

    <script src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
    <script src="http://cdnjs.cloudflare.com/ajax/libs/gsap/1.18.2/TweenMax.min.js"></script>
    <script src="https://polyfill.io/v2/polyfill.min.js?features=IntersectionObserver"></script>
    <script src="http://cdnjs.cloudflare.com/ajax/libs/ScrollMagic/2.0.5/ScrollMagic.min.js"></script>
    <script src="http://cdnjs.cloudflare.com/ajax/libs/ScrollMagic/2.0.5/plugins/animation.gsap.js"></script>
    <script src="https://npmcdn.com/flickity@2/dist/flickity.pkgd.js"></script>
    <script src="/javascript/project-page.js"></script>
    <script src="/javascript/global.js"></script>
    <script src="/javascript/include.js"></script>
    <script>
        $(function() {
            // $("#footerJS").load("../footerNav.html");
            $("#footerJS").load("../footerNav.html");
        });
    </script>

</body>

</html>